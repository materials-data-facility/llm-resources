
<div align="center">

<!-- title -->

<!--lint ignore no-dead-urls-->

# LLM Resources 
<!-- subtitle -->


<!-- description -->

**A List of LLM resources to help get projects started**

This list is focused on collecting the tools needed to get LLM-based projects started quickly including free resources, links to the most common APIs, examples, and template projects. 

</div>

<!-- TOC -->

## Contents
Contents

- ğŸ”Œ APIs
- ğŸ’» Local Models
- ğŸ Offers and Promotions
- ğŸ§° Software and Tools
- ğŸ“š Tutorials and Examples

<!-- CONTENT -->

## ğŸ“ Basics 

- If you only have time for 8 minutes, let â€œRyan Goslingâ€ explain LLMs to you. [YouTube](https://youtu.be/xU_MFS_ACrU?si=gGVQh6l6dGrnbLjJ)
- â€œGetting started with huggingface.co in 15 minâ€. AssemblyAI, [YouTube](https://youtu.be/QEaBAZQCtwE?si=1iEMlPOzEx75_zXe). This is what I used to run my first open-source model. Gives you some understanding of how to use the transformers Python library and what Models and Tasks are.
- â€œNeural Networksâ€ (visualized). 3Blue1Brown (Grant Sanderson), [YouTube](https://youtu.be/aircAruvnKk?si=f6ihC9TuIh_Wwhqg), [homepage](https://www.3blue1brown.com/#lessons): Gives you a nice intuition on how neural networks in general and transformers work in particular. I recommend the transformer/attention video (chapter 6) as it also gives a good sense of the scale of an LLM like GPT-3.
- â€œNeural networks from zero to heroâ€ (i.e. from gradient descent to transformers), Andrej Karpathy, [YouTube](https://youtu.be/VMj-3S1tku0?si=HQHzq6PaD_2P470t): step-by-step coding instructions that I recommend following and reproducing to get some technical understanding of what is happening in NN and LLMs

## ğŸ”Œ APIs

- [OpenAI](https://platform.openai.com) - Access to GPT models and other AI capabilities.
- [Hugging Face](https://huggingface.co/models) - API access to a wide range of machine learning models. [How to use Llama on HF](https://www.youtube.com/watch?v=LA-hZDnn5Hc)
- [Google Vertex AI](https://cloud.google.com/generative-ai-studio) - A suite of AI and machine learning APIs provided by Google Cloud.  $150 credits upon signup
- [Azure AI Studio](https://azure.microsoft.com/en-us/products/ai-studio) - A collection of AI services and APIs offered by Microsoft Azure. [Students start with $100 free Azure credits](https://azure.microsoft.com/en-us/free/students) <== you will need an account here to use AI Studio
- [Groq](https://console.groq.com/docs/models) Exceptionally fast inference for a variety of models. Fairly high rate limits for free tier, though can't find exact documentation.

## ğŸ’» Local Models
- [Llama](https://simonwillison.net/2024/Apr/22/llama-3/) Run llama3 locally using `llm` package
- Mixtral
- Phi
- [Apple OpenELM](https://huggingface.co/apple/OpenELM), a family of Open Efficient Language Models. 270M, 450M, 1.1B and 3B parameters

## ğŸ Offers and Promotions
- [GitHub student developer pack](https://education.github.com/pack#offers)
- 15$ at [NLP Cloud](https://nlpcloud.com/)
- [Google Colab](https://www.google.com/search?q=colab&sca_esv=e3b0e6080babb4e8&sca_upv=1&gbv=2&sxsrf=ACQVn0-TPjEhC22olFvD6F_Q1bvHvcBnhA:1714493958904&ei=BhoxZpDQNsToi-gPoZudMA&ved=0ahUKEwiQ647bq-qFAxVE9AIHHaFNBwYQ4dUDCBA&uact=5&oq=colab&gs_lp=Egxnd3Mtd2l6LXNlcnAiBWNvbGFiMgoQABiABBhDGIoFMgsQABiABBiRAhiKBTIKEAAYgAQYQxiKBTIKEAAYgAQYQxiKBTIKEAAYgAQYQxiKBTIIEAAYgAQYywEyBRAAGIAEMgoQABiABBgKGMsBMgoQABiABBgUGIcCMgUQLhiABEiKBlDlAViGBXABeAGQAQCYAXmgAZcEqgEDMi4zuAEDyAEA-AEBmAIGoAKjBMICBxAjGLADGCfCAgoQABiwAxjWBBhHwgIEECMYJ8ICChAuGIAEGEMYigXCAgsQLhiABBjRAxjHAcICChAjGIAEGCcYigXCAhAQLhiABBjRAxhDGMcBGIoFwgINEC4YgAQYQxjUAhiKBZgDAIgGAZAGCJIHAzMuM6AHzjc&sclient=gws-wiz-serp)
- [LightningStudio](https://lightning.ai/)
- [Azure](https://azure.microsoft.com/en-us/free/students)

## ğŸ§° Software and Tools
- [LLM CLI Utility](https://llm.datasette.io/en/stable/index.html) from Datasette
- [huggingface.co](http://huggingface.co/), The GitHub for models. Use and share your NN models.
- [LangChain](https://github.com/langchain-ai/langchain), LangChain is a framework for developing applications powered by LLMs
- [axolotl](https://github.com/OpenAccess-AI-Collective/axolotl), if you want to get into fine-tuning
- on new Macs, [mlx](https://github.com/ml-explore/mlx) is a very fast way to run LLMs
- [access to LLMs via API](https://console.groq.com/settings/limits) via Groq (limited to 30 req/min)
- 100 req/day at [Awan LLM](https://www.awanllm.com/pricing)
- [Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM?tab=readme-ov-file#llm-training-frameworks), a very deep awesome list with all the relevant papers and projects.

## Contributing

[Contributions of any kind welcome, just follow the guidelines](contributing.md)!

### Contributors

[Thanks goes to these contributors](https://github.com/materials-data-facility/awesome-bayesian-optimization/graphs/contributors)!

Thank you also to Sterling Baird, who started collecting many of the software links included here. 
